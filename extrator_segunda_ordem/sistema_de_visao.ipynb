{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de visão computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow, imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import filters\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import histogram, equalize_hist\n",
    "from skimage.filters import threshold_otsu, threshold_niblack\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage.feature  import graycomatrix, graycoprops, local_binary_pattern\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,cohen_kappa_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    \n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = rgb2gray(image)\n",
    "\n",
    "    # Binariza a imagem\n",
    "    thresh_mean = filters.threshold_mean(gray)\n",
    "    binary_image = np.where(gray > thresh_mean, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    longest_contour = contours[0]\n",
    "    longest_length = len(longest_contour)\n",
    "    \n",
    "    # Percorrer os contornos e encontrar o mais longo\n",
    "    for contour in contours:\n",
    "        length = len(contour)\n",
    "        if length > longest_length:\n",
    "            longest_contour = contour\n",
    "            longest_length = length\n",
    "            \n",
    "    x, y, w, h = cv2.boundingRect(longest_contour)\n",
    "    image = image[y:y+h, x:x+w]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista os arquivos do diretorio.\n",
    "#tumor_paths = glob.glob('imagens/*.jpg')\n",
    "#no_tumor_paths = glob.glob('imagens/*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler as imagens e faz o corte.\n",
    "#imgs_tumor = [imread(i) for i in tumor_paths]\n",
    "#imgs_tumor_crop = [crop_image(img) for img in imgs_tumor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_no_tumor = [imread(i) for i in no_tumor_paths]\n",
    "#imgs_no_tumor_crop = [crop_image(img) for img in imgs_no_tumor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_crop(imgs, path):\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        imsave(path+str(i)+'.jpg', imgs[i])\n",
    "    \n",
    "    return 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações de Intensidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alargamento_de_contraste(image, k, E):\n",
    "  return 1/(1 + (k/image)**E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativo(image):\n",
    "  return 255 - image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logaritmica(image, c):\n",
    "  return c * np.log(1 + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potencia(image, gamma):\n",
    "  return (image / 255) ** gamma * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_transformation(imgs, type):\n",
    "    \n",
    "    if type == 'al':\n",
    "        imgs_it = [Alargamento_de_contraste(img, 5, 2) for img in imgs]\n",
    "    \n",
    "    elif type == 'neg':\n",
    "        imgs_it = [negativo(img) for img in imgs]\n",
    "    \n",
    "    elif type == 'log':\n",
    "        imgs_it = [logaritmica(img, 0.5) for img in imgs]\n",
    "    \n",
    "    elif type == 'po':\n",
    "        imgs_it = [potencia(img, 3) for img in imgs]\n",
    "    \n",
    "    return imgs_it\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando as imagens pré-processadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader( no_tumor, tumor):\n",
    " \n",
    "    y = np.concatenate((np.zeros(len(no_tumor)), np.ones(len(tumor))), axis=0)\n",
    "\n",
    "    x = no_tumor + tumor\n",
    "\n",
    "    x = [resize(imread(img),(340,360)) for img in x]\n",
    "    x = [(rgb2gray(img) * 255).astype(np.uint8) for img in x]\n",
    "    \n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_0 = glob.glob('dataset/testing/no_tumor/*.jpg')\n",
    "test_1 = glob.glob('dataset/testing/tumor/*.jpg')\n",
    "x_test, y_test = dataloader(test_0,test_1)\n",
    "\n",
    "train_0 = glob.glob('dataset/training/no_tumor/*.jpg')\n",
    "train_1 = glob.glob('dataset/training/tumor/*.jpg')\n",
    "x_train, y_train = dataloader(train_0,train_1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_seg(img, k, cen='min'):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    img_train = img.reshape(-1, 1)\n",
    "    result = kmeans.fit(img_train)\n",
    "    \n",
    "    labels = result.labels_\n",
    "    cluster_centers = result.cluster_centers_\n",
    "    \n",
    "    cluster_centers = cluster_centers.reshape(1, -1)\n",
    "    cluster_centers = list(cluster_centers[0])\n",
    "    \n",
    "    index_min = cluster_centers.index(min(cluster_centers))\n",
    "    index_max = cluster_centers.index(max(cluster_centers))\n",
    "\n",
    "    if cen == 'min':\n",
    "        labels = (labels != index_min)\n",
    "    elif cen == 'max':\n",
    "        labels = (labels != index_max)\n",
    "    \n",
    "    img_final = labels.reshape(img.shape)\n",
    "    \n",
    "    return img_final.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(images):\n",
    "    \n",
    "    imgs_blur = [filters.gaussian(img, sigma=4) for img in images]\n",
    "    k_seg = [kmeans_seg(img, 3) for img in imgs_blur]\n",
    "    imgs_seg = [images[i] * k_seg[i] for i in range(len(images))]\n",
    "\n",
    "    return imgs_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seg = segmentation(x_train)\n",
    "X_test_seg = segmentation(x_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descritores de características"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glcm(images, distance):\n",
    "    \n",
    "    features = np.zeros((len(images), 6))\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        matrix0 = graycomatrix(img, [distance], [0], normed=True)\n",
    "        matrix1 = graycomatrix(img, [distance], [np.pi/4], normed=True)\n",
    "        matrix2 = graycomatrix(img, [distance], [np.pi/2], normed=True)\n",
    "        matrix3 = graycomatrix(img, [distance], [3*np.pi/4], normed=True)\n",
    "        matrix = (matrix0+matrix1+matrix2+matrix3)/4\n",
    "\n",
    "        props = np.zeros(6)\n",
    "        props[0] = graycoprops(matrix,'contrast')\n",
    "        props[1] = graycoprops(matrix,'dissimilarity')\n",
    "        props[2] = graycoprops(matrix,'homogeneity')\n",
    "        props[3] = graycoprops(matrix,'energy')\n",
    "        props[4] = graycoprops(matrix,'correlation')\n",
    "        props[5] = graycoprops(matrix,'ASM')\n",
    "        features[i] = props\n",
    "    \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando histograma, para tranformar saida do lbp em uma matriz unidimensional\n",
    "def create_histograms(image, sub_images_num, bins_per_sub_images):\n",
    "\n",
    "    grid = np.arange(0, image.shape[1]+1, image.shape[1]//sub_images_num)\n",
    "\n",
    "    sub_image_histograms = []\n",
    "\n",
    "    for i in range(1, len(grid)):\n",
    "        for j in range(1, len(grid)):\n",
    "            sub_image = image[grid[i-1]:grid[i], grid[j-1]:grid[j]]\n",
    "\n",
    "            sub_image_histogram = np.histogram(sub_image, bins=bins_per_sub_images)[0]\n",
    "            sub_image_histograms.append(sub_image_histogram)\n",
    "\n",
    "    histogram = np.array(sub_image_histograms).flatten()\n",
    "        \n",
    "        \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp\n",
    "\n",
    "def extract_lbp(images, n_points):\n",
    "    \n",
    "    ft = []\n",
    "    for i, img in enumerate(images):\n",
    "        lpb = local_binary_pattern(img, n_points,1,method='default')\n",
    "        ft.append(create_histograms(lpb, 3, 64))\n",
    "    \n",
    "   \n",
    "    return np.array(ft)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, points, distance):\n",
    "    \n",
    "    x_glcm = glcm(images, distance) \n",
    "    \n",
    "    x_lbp = extract_lbp(images,points)\n",
    "    \n",
    "    return x_glcm, x_lbp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_glcm, x_train_lbp = extract_features(x_train, 8, 5)\n",
    "x_test_glcm,x_test_lbp  = extract_features(x_test, 8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_glcm_ns, x_train_lbp_ns = extract_features(x_train, 8, 5)\n",
    "x_test_glcm_ns,  x_test_lbp_ns = extract_features(x_test, 8, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model,x,y, test):\n",
    "    acc_rf = []\n",
    "    kappa = []\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test)\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        acc_rf.append(accuracy_score(y_test, pred))\n",
    "        kappa.append(cohen_kappa_score(y_test,pred))\n",
    "        \n",
    "    return np.mean(acc_rf),np.std(acc_rf), np.mean(kappa)\n",
    "    \n",
    "\n",
    "def classfication(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    x = np.append(x_train,x_test,0)\n",
    "    y = np.append(y_train,y_test,0)\n",
    "    c_rf = RandomForestClassifier()\n",
    "    \n",
    "    print(\"Random Forest: Acc = {} Std = {}, kappa = {}\".format(*cross_validation(c_rf,x,y,0.1)))\n",
    "    \n",
    "    \n",
    "    mlp = MLPClassifier()\n",
    "    print(\" MLP : Acc = {} Std = {}, kappa = {}\".format(*cross_validation(mlp,x,y,0.1)))\n",
    "    \n",
    "    model_svm = SVC()\n",
    "    print(\"SVC : Acc = {} Std = {}, kappa = {}\".format(*cross_validation(model_svm,x,y,0.1)))\n",
    "    \n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Acc = 0.9102597402597402 Std = 0.03301333442141993, kappa = 0.8181828015211714\n",
      " MLP : Acc = 0.5428571428571428 Std = 0.080498530999022, kappa = 0.08712063087355199\n",
      "SVC : Acc = 0.6645454545454546 Std = 0.05758550514759241, kappa = 0.3123016527845898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication(x_train_glcm, y_train, x_test_glcm, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Acc = 0.9149350649350648 Std = 0.031243147334336134, kappa = 0.8283126872980879\n",
      " MLP : Acc = 0.8374025974025975 Std = 0.0669676681554246, kappa = 0.6713929768455703\n",
      "SVC : Acc = 0.8316883116883118 Std = 0.047359703061889045, kappa = 0.6624330737998048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication(x_train_lbp, y_train, x_test_lbp, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Acc = 0.9124675324675324 Std = 0.0323175757779875, kappa = 0.8226047302144112\n",
      " MLP : Acc = 0.5451948051948051 Std = 0.08309618248714307, kappa = 0.08408726482769174\n",
      "SVC : Acc = 0.6737662337662339 Std = 0.055716556124840944, kappa = 0.33523197092328544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfication(x_train_glcm_ns, y_train, x_test_glcm_ns, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Acc = 0.9197402597402597 Std = 0.03214803841225954, kappa = 0.8381764160862187\n"
     ]
    }
   ],
   "source": [
    "classfication(x_train_lbp_ns, y_train, x_test_lbp_ns, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(features_test_0[:,0],features_test_0[:,3], c=labels_test_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33fb81b30dbad5efdfd8e59d2eb6c9bb746a620a6b7a6df18f82036835af372d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
